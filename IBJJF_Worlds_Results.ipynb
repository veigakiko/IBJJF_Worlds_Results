{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Previsão de Campeões Mundiais** de *Jiu-Jitsu* em 2024 com **Machine Learning**"
      ],
      "metadata": {
        "id": "4AKE57zeFKoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JDpExV8aV5aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "url = 'https://www.ibjjfdb.com/ChampionshipResults/2025/PublicResults'\n",
        "response = requests.get(url)\n",
        "html = response.text\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "title = soup.title.get_text().strip()\n",
        "elements = soup.find_all(['div', 'h4'], class_=['athlete-item', 'subtitle', 'position-athlete'])\n",
        "championships = [elem.get_text().strip() for elem in elements if elem['class'] == ['athlete-item']]\n",
        "categories = [elem.get_text().strip() for elem in elements if elem['class'] == ['subtitle']]\n",
        "position = [elem.get_text().strip() for elem in elements if elem['class'] == ['position-athlete']]\n",
        "data = {'title': title, 'categories': categories,'championships': championships,'position': position}\n",
        "\n",
        "with open('data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "with open('data.json', 'r', encoding='utf-8') as f:\n",
        "    json_file = json.load(f)\n",
        "\n",
        "resultsdf = []\n",
        "for t in range(0,len(json_file['championships'])):\n",
        "    athlete_name =  ((json_file['championships'][t][52:][:80])).strip()\n",
        "    academie_name = ((json_file['championships'][t][200:])).strip()\n",
        "    position_name = json_file['position'][t]\n",
        "    categories_name = json_file['categories'][3]\n",
        "    resultsdf.append((position_name, athlete_name, academie_name, categories_name))\n",
        "\n",
        "df = pd.DataFrame(resultsdf, columns=['Results','Name','Academy','Category'])\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "wg6itwWxVuiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "iC22QaIpDYhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# Define the URL\n",
        "url = 'https://www.ibjjfdb.com/ChampionshipResults/2025/PublicResults'\n",
        "\n",
        "# Send an HTTP GET request\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Raise an error if the request fails\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract title\n",
        "title = soup.title.get_text().strip()\n",
        "\n",
        "# Find all relevant elements\n",
        "elements = soup.find_all(['div', 'h4'], class_=['athlete-item', 'subtitle', 'position-athlete'])\n",
        "\n",
        "# Initialize lists to store data\n",
        "championships = []\n",
        "categories = []\n",
        "position = []\n",
        "\n",
        "# Extract data into lists\n",
        "for elem in elements:\n",
        "    if 'athlete-item' in elem['class']:\n",
        "        championships.append(elem.get_text().strip())\n",
        "    elif 'subtitle' in elem['class']:\n",
        "        categories.append(elem.get_text().strip())\n",
        "    elif 'position-athlete' in elem['class']:\n",
        "        position.append(elem.get_text().strip())\n",
        "\n",
        "# Create a dictionary to store the data\n",
        "data = {'title': title, 'categories': categories, 'championships': championships, 'position': position}\n",
        "\n",
        "# Save the data to a JSON file\n",
        "with open('data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Read the data from the JSON file\n",
        "with open('data.json', 'r', encoding='utf-8') as f:\n",
        "    json_file = json.load(f)\n",
        "\n",
        "# Create a list of tuples for DataFrame construction\n",
        "resultsdf = [(pos, champ[52:][:80].strip(), champ[200:].strip(), cat) for pos, champ, cat in zip(json_file['position'], json_file['championships'], json_file['categories'])]\n",
        "\n",
        "# Create a DataFrame from the list of tuples\n",
        "df = pd.DataFrame(resultsdf, columns=['Results', 'Name', 'Academy', 'Category'])\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "S0MnGQ3iB2k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ME3FPVyQFzZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# Define the URL of the website to scrape\n",
        "url = 'https://www.ibjjfdb.com/ChampionshipResults/2025/PublicResults'\n",
        "\n",
        "# Send an HTTP GET request to the URL and check for errors\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Parse the HTML content of the response using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract the title of the website\n",
        "title = soup.title.get_text().strip()\n",
        "\n",
        "# Find all the elements that contain the relevant data\n",
        "elements = soup.find_all(['div', 'h4'], class_=['athlete-item', 'subtitle', 'position-athlete'])\n",
        "\n",
        "# Initialize empty lists to store the data\n",
        "championships, categories, position = [], [], []\n",
        "\n",
        "# Loop through the elements and extract the data into the lists\n",
        "for elem in elements:\n",
        "    class_name = elem['class'][0] if elem['class'] else None\n",
        "    text = elem.get_text().strip()\n",
        "\n",
        "    if class_name == 'athlete-item':\n",
        "        championships.append(text)\n",
        "    elif class_name == 'subtitle':\n",
        "        categories.append(text)\n",
        "    elif class_name == 'position-athlete':\n",
        "        position.append(text)"
      ],
      "metadata": {
        "id": "62t1x14XFzWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "id": "rPJt7SoVFy3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "championships"
      ],
      "metadata": {
        "id": "PIWd33twF9Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position"
      ],
      "metadata": {
        "id": "8HAopGEDGCSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# Define the URL of the website to scrape\n",
        "url = 'https://www.ibjjfdb.com/ChampionshipResults/2025/PublicResults'\n",
        "\n",
        "# Send an HTTP GET request to the URL and check for errors\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Parse the HTML content of the response using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract the title of the website\n",
        "title = soup.title.get_text().strip()\n",
        "\n",
        "# Find all the elements that contain the relevant data\n",
        "elements = soup.find_all(['div', 'h4'], class_=['athlete-item', 'subtitle', 'position-athlete'])\n",
        "\n",
        "# Initialize empty lists to store the data\n",
        "championships, categories, position = [], [], []\n",
        "\n",
        "# Loop through the elements and extract the data into the lists\n",
        "for elem in elements:\n",
        "    class_name = elem['class'][0] if elem['class'] else None\n",
        "    text = elem.get_text().strip()\n",
        "\n",
        "    if class_name == 'athlete-item':\n",
        "        championships.append(text)\n",
        "    elif class_name == 'subtitle':\n",
        "        categories.append(text)\n",
        "    elif class_name == 'position-athlete':\n",
        "        position.append(text)\n",
        "\n",
        "# Create a dictionary to store the data with keys and values\n",
        "data = {'title': title, 'categories': categories, 'championships': championships, 'position': position}\n",
        "\n",
        "# Save the data to a JSON file with UTF-8 encoding and indentation\n",
        "with open('data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Read the data from the JSON file with UTF-8 encoding\n",
        "with open('data.json', 'r', encoding='utf-8') as f:\n",
        "    json_file = json.load(f)\n",
        "\n",
        "# Create a list of tuples for DataFrame construction by slicing and formatting the strings\n",
        "resultsdf = [(pos, champ[52:][:80].strip(), champ[200:].strip(), cat) for pos, champ, cat in zip(json_file['position'], json_file['championships'], json_file['categories'])]\n",
        "\n",
        "# Create a DataFrame from the list of tuples with column names\n",
        "df = pd.DataFrame(resultsdf, columns=['Results', 'Name', 'Academy', 'Category'])\n",
        "df"
      ],
      "metadata": {
        "id": "D3NQ0-QEDdC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}